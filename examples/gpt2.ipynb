{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd1e09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import sys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50534138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parent directory path\n",
    "parent_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('.'))), 'nnetflow')\n",
    "# Add parent directory to Python path if not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df75ee79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/nnetflow'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df417f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspaces/nnetflow', '/home/codespace/.python/current/lib/python312.zip', '/home/codespace/.python/current/lib/python3.12', '/home/codespace/.python/current/lib/python3.12/lib-dynload', '', '/workspaces/nnetflow/env/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "605fe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnetflow.engine import Tensor \n",
    "from nnetflow import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a74959ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b05bc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small config for testing (much less memory intensive)\n",
    "GPT_CONFIG_TINY = {\n",
    "    \"vocab_size\": 50257,    # Keep full vocab for compatibility\n",
    "    \"context_length\": 64,   # Reduced from 1024\n",
    "    \"emb_dim\": 128,        # Reduced from 768\n",
    "    \"n_heads\": 4,          # Reduced from 12\n",
    "    \"n_layers\": 4,         # Reduced from 12\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "# Original GPT-2 124M config (commented out - too large for testing)\n",
    "# GPT_CONFIG_124M = {\n",
    "#     \"vocab_size\": 50257,\n",
    "#     \"context_length\": 1024,\n",
    "#     \"emb_dim\": 768,\n",
    "#     \"n_heads\": 12,\n",
    "#     \"n_layers\": 12,\n",
    "#     \"drop_rate\": 0.1,\n",
    "#     \"qkv_bias\": False\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44766df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small config for testing (much less memory intensive)\n",
    "GPT_CONFIG_TINY = {\n",
    "    \"vocab_size\": 50257,    # Keep full vocab for compatibility\n",
    "    \"context_length\": 128,  # Make this larger than our block_size\n",
    "    \"emb_dim\": 128,        # Reduced from 768\n",
    "    \"n_heads\": 4,          # Reduced from 12\n",
    "    \"n_layers\": 4,         # Reduced from 12\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f7a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87841cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84567e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward:\n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.layers = [\n",
    "            layers.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            layers.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        ]\n",
    "    def __call__(self,x): \n",
    "        # Fix indexing syntax\n",
    "        return self.layers[1](self.layers[0](x).gelu())\n",
    "    def parameters(self):\n",
    "        parameters = [] \n",
    "        parameters.extend(self.layers[0].parameters())\n",
    "        parameters.extend(self.layers[1].parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68aba6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,dropout,qkv_bias=False):\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\" \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads \n",
    "        self.W_query = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.W_key = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.W_value = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.out_proj = layers.Linear(d_out,d_out)\n",
    "        self.dropout = layers.Dropout(dropout) \n",
    "        mask = np.triu(np.ones((context_length, context_length)), k=1)\n",
    "        self.mask = Tensor(mask,requires_grad=False) \n",
    "    \n",
    "    def __call__(self,x):\n",
    "        B,T,D_in = x.shape \n",
    "        Q = self.W_query(x) # (B,T,D_out) \n",
    "        K = self.W_key(x) \n",
    "        V = self.W_value(x) \n",
    "        Q = Q.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "        K = K.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "        V = V.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "\n",
    "        # attention scores \n",
    "        attn_scores = (Q @ K.transpose((0,1,3,2))) / (self.head_dim ** 0.5)  # Fix transpose axes\n",
    "        mask = self.mask[:T,:T].bool()\n",
    "        attn_scores = attn_scores.masked_fill(mask[None,None,:,:],float('-inf'))\n",
    "        #softmax and dropout \n",
    "        attn_weights = attn_scores.softmax(axis=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context = attn_weights @ V \n",
    "        context = context.transpose((0,2,1,3)).reshape((B,T,self.d_out))  # Fix transpose and reshape\n",
    "        context = self.out_proj(context) \n",
    "        return context \n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = [] \n",
    "        parameters.extend(self.W_key.parameters())\n",
    "        parameters.extend(self.W_query.parameters())\n",
    "        parameters.extend(self.W_value.parameters())\n",
    "        parameters.extend(self.out_proj.parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9be8829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock: \n",
    "    def __init__(self,config:dict):\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in= config['emb_dim'],\n",
    "            d_out = config['emb_dim'], \n",
    "            context_length=config['context_length'], \n",
    "            num_heads = config['n_heads'], \n",
    "            dropout = config['drop_rate'], \n",
    "            qkv_bias=config['qkv_bias'] \n",
    "        ) \n",
    "\n",
    "        self.ff = FeedForward(config) \n",
    "        # Add embedding dimension to LayerNorm\n",
    "        self.norm1 = layers.LayerNorm(dim=config['emb_dim']) \n",
    "        self.norm2 = layers.LayerNorm(dim=config['emb_dim']) \n",
    "        self.drop_shortcut = layers.Dropout(config['drop_rate']) \n",
    "    def __call__(self,x):\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        # Add second normalization and feedforward\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x \n",
    "\n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        parameters.extend(self.ff.parameters())\n",
    "        parameters.extend(self.norm1.parameters())\n",
    "        parameters.extend(self.norm2.parameters())\n",
    "        parameters.extend(self.att.parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d5dc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self,config:dict): \n",
    "        self.tok_emb = layers.Embedding(config['vocab_size'],config['emb_dim']) \n",
    "        self.pos_emb = layers.Embedding(config['context_length'],config['emb_dim'])\n",
    "        self.drop_emb = layers.Dropout(config['drop_rate']) \n",
    "        self.trf_blocks = [TransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        self.final_norm = layers.LayerNorm(dim=config['emb_dim'])  # Add embedding dimension\n",
    "        self.out_head = layers.Linear( \n",
    "            config['emb_dim'], config['vocab_size'],bias=False\n",
    "        )\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] \n",
    "        params.extend(self.tok_emb.parameters())\n",
    "        params.extend(self.pos_emb.parameters())\n",
    "        params.extend(self.final_norm.parameters())\n",
    "        params.extend(self.out_head.parameters())\n",
    "        for block in self.trf_blocks:\n",
    "            params.extend(block.parameters())\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,in_idx:Tensor): \n",
    "        batch_size , seq_len = in_idx.shape \n",
    "        tok_embeds = self.tok_emb(in_idx) \n",
    "        pos_embeds = self.pos_emb(\n",
    "            Tensor(np.arange(seq_len))\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds # broadcasting will happen here \n",
    "        x = self.drop_emb(x) \n",
    "        for block in self.trf_blocks:\n",
    "            x = block(x) \n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x) \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5fc02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self,config:dict): \n",
    "        self.tok_emb = layers.Embedding(config['vocab_size'],config['emb_dim']) \n",
    "        self.pos_emb = layers.Embedding(config['context_length'],config['emb_dim'])\n",
    "        self.drop_emb = layers.Dropout(config['drop_rate']) \n",
    "        self.trf_blocks = [TransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        self.final_norm = layers.LayerNorm(dim=config['emb_dim'])  # Add embedding dimension\n",
    "        self.out_head = layers.Linear( \n",
    "            config['emb_dim'], config['vocab_size'],bias=False\n",
    "        )\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] \n",
    "        params.extend(self.tok_emb.parameters())\n",
    "        params.extend(self.pos_emb.parameters())\n",
    "        params.extend(self.final_norm.parameters())\n",
    "        params.extend(self.out_head.parameters())\n",
    "        for block in self.trf_blocks:\n",
    "            params.extend(block.parameters())\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,in_idx): \n",
    "        # Input can be tensor or numpy array, convert to numpy for indexing\n",
    "        if isinstance(in_idx, Tensor):\n",
    "            in_idx = in_idx.data\n",
    "            \n",
    "        batch_size, seq_len = in_idx.shape \n",
    "        \n",
    "        # Token embeddings from input indices\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # Create position indices (0 to seq_len-1) and ensure they're in bounds\n",
    "        positions = np.arange(seq_len).astype(np.int64)\n",
    "        pos_embeds = self.pos_emb(positions)[None]  # Add batch dimension [1, seq_len, emb_dim]\n",
    "        \n",
    "        # Add position embeddings (broadcasting will handle batch dimension)\n",
    "        x = tok_embeds + pos_embeds  # Broadcasting: [batch_size, seq_len, emb_dim] + [1, seq_len, emb_dim]\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # Transform through blocks\n",
    "        for block in self.trf_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b94dbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self,config:dict): \n",
    "        self.tok_emb = layers.Embedding(config['vocab_size'],config['emb_dim']) \n",
    "        self.pos_emb = layers.Embedding(config['context_length'],config['emb_dim'])\n",
    "        self.drop_emb = layers.Dropout(config['drop_rate']) \n",
    "        self.trf_blocks = [TransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        self.final_norm = layers.LayerNorm(dim=config['emb_dim'])  # Add embedding dimension\n",
    "        self.out_head = layers.Linear( \n",
    "            config['emb_dim'], config['vocab_size'],bias=False\n",
    "        )\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] \n",
    "        params.extend(self.tok_emb.parameters())\n",
    "        params.extend(self.pos_emb.parameters())\n",
    "        params.extend(self.final_norm.parameters())\n",
    "        params.extend(self.out_head.parameters())\n",
    "        for block in self.trf_blocks:\n",
    "            params.extend(block.parameters())\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,in_idx): \n",
    "        # Input can be tensor or numpy array, convert to numpy for indexing\n",
    "        if isinstance(in_idx, Tensor):\n",
    "            in_idx = in_idx.data\n",
    "            \n",
    "        batch_size, seq_len = in_idx.shape \n",
    "        \n",
    "        # Token embeddings from input indices\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        \n",
    "        # Position embeddings from position indices (0 to seq_len-1)\n",
    "        positions = np.arange(seq_len)  # use numpy array directly\n",
    "        pos_embeds = self.pos_emb(positions)\n",
    "        \n",
    "        # Add position embeddings (broadcasting will handle batch dimension)\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        \n",
    "        # Transform through blocks\n",
    "        for block in self.trf_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41aaf4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "995ba7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 13,673,984\n"
     ]
    }
   ],
   "source": [
    "# Create model with tiny config for testing\n",
    "model = GPT2(GPT_CONFIG_TINY)  # Much smaller model\n",
    "print(f\"Model parameter count: {sum(t.data.size for t in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eca500c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter count: 13,673,984\n"
     ]
    }
   ],
   "source": [
    "# Recreate model with tiny config\n",
    "model = GPT2(GPT_CONFIG_TINY)  # Much smaller model\n",
    "print(f\"Model parameter count: {sum(t.data.size for t in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a603a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b0157c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in model.parameters():\n",
    "   total_params +=  t.data.size\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21f606ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13673984"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2992f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple pretraining :) \n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d1c3568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/rakibulhasanshaon69/the-verdict-txt/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rakibulhasanshaon69/the-verdict-txt\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b1d8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "922b96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the-verdict.txt']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a164e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + '/the-verdict.txt','r',encoding='utf-8') as f: \n",
    "    raw_text = f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b0735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 \n",
    "context_size = GPT_CONFIG_124M['context_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ac9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cd2064b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in dataset: 5145\n",
      "Train tokens: 4630, Val tokens: 515\n"
     ]
    }
   ],
   "source": [
    "# --- Tokenization and dataset encoding\n",
    "import tiktoken\n",
    "from nnetflow import losses as nf_losses\n",
    "from nnetflow import optim as nf_optim\n",
    "\n",
    "# Use GPT-2 BPE tokenizer (gpt2) — adjust if you prefer a different encoding\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Encode the full raw text into token ids (a list of ints)\n",
    "# This may take some memory for very large datasets; for demonstration we keep the full array\n",
    "ids = np.array(enc.encode(raw_text), dtype=np.int64)\n",
    "print(f\"Total tokens in dataset: {ids.size}\")\n",
    "\n",
    "# Simple train/val split (keep small val for quick checks)\n",
    "split_idx = int(0.9 * len(ids))\n",
    "train_ids = ids[:split_idx]\n",
    "val_ids = ids[split_idx:]\n",
    "print(f\"Train tokens: {train_ids.size}, Val tokens: {val_ids.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "871e6a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape, yb.shape = (4, 32) (4, 32)\n"
     ]
    }
   ],
   "source": [
    "# --- Batching helper\n",
    "import random\n",
    "\n",
    "def get_batch(split='train', batch_size=16, block_size=128):\n",
    "    data = train_ids if split == 'train' else val_ids\n",
    "    n = data.shape[0]\n",
    "    starts = np.random.randint(0, n - block_size - 1, size=batch_size)\n",
    "    x_batch = np.stack([data[s:s+block_size] for s in starts], axis=0)\n",
    "    y_batch = np.stack([data[s+1:s+1+block_size] for s in starts], axis=0)\n",
    "    # Return numpy int arrays (Embedding handles numpy indexes)\n",
    "    return x_batch.astype(np.int64), y_batch.astype(np.int64)\n",
    "\n",
    "# Quick sanity check: sample one batch and show shapes\n",
    "xb,yb = get_batch(batch_size=4, block_size=32)\n",
    "print('xb.shape, yb.shape =', xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "13a55a75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input tensor must be 2D, got 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m xb, yb = get_batch(split=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, batch_size=batch_size, block_size=block_size)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (B, T, V)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Convert targets to one-hot and compute CE loss\u001b[39;00m\n\u001b[32m     33\u001b[39m targets_oh = to_one_hot(yb, GPT_CONFIG_124M[\u001b[33m'\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mGPT2.__call__\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Transform through blocks\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.trf_blocks:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     x = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m     45\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.out_head(x)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mTransformerBlock.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     18\u001b[39m shortcut = x \n\u001b[32m     19\u001b[39m x = \u001b[38;5;28mself\u001b[39m.norm1(x)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_shortcut(x)\n\u001b[32m     22\u001b[39m x = x + shortcut\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mMultiHeadAttention.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m     16\u001b[39m     B,T,D_in = x.shape \n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     Q = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,D_out) \u001b[39;00m\n\u001b[32m     18\u001b[39m     K = \u001b[38;5;28mself\u001b[39m.W_key(x) \n\u001b[32m     19\u001b[39m     V = \u001b[38;5;28mself\u001b[39m.W_value(x) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/nnetflow/nnetflow/layers.py:18\u001b[39m, in \u001b[36mLinear.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,x:Tensor) -> Tensor:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m x.shape[-\u001b[32m1\u001b[39m] == \u001b[38;5;28mself\u001b[39m.in_features, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput feature size mismatch, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x.shape) == \u001b[32m2\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput tensor must be 2D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x.shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m  \n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# x : (batch_size, in_features) \u001b[39;00m\n\u001b[32m     20\u001b[39m     \u001b[38;5;66;03m# weight : (in_features, out_features) \u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# x @ weight (batch_size,in_features) @ (in_features, out_features) = (batch_size, out_features)\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_bias:\n",
      "\u001b[31mAssertionError\u001b[39m: Input tensor must be 2D, got 3D"
     ]
    }
   ],
   "source": [
    "# --- Training loop (small, illustrative)\n",
    "# Hyperparameters (tweak as needed)\n",
    "lr = 3e-4\n",
    "batch_size = 8\n",
    "block_size = 128  # context length for training\n",
    "max_steps = 200   # number of optimization steps to run (small for demo)\n",
    "print_every = 20\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = nf_optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# A tiny helper to convert integer target arrays to one-hot Tensor (no grad)\n",
    "def to_one_hot(targets_np, vocab_size):\n",
    "    B, T = targets_np.shape\n",
    "    oh = np.zeros((B, T, vocab_size), dtype=np.float64)\n",
    "    # advanced indexing: for each (b,t) set the token index to 1\n",
    "    b_idx = np.arange(B)[:, None]\n",
    "    t_idx = np.arange(T)[None, :]\n",
    "    oh[b_idx, t_idx, targets_np] = 1.0\n",
    "    return Tensor(oh, requires_grad=False)\n",
    "\n",
    "# Training loop (causal next-token prediction)\n",
    "for step in range(1, max_steps + 1):\n",
    "    # zero gradients on parameters\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    xb, yb = get_batch(split='train', batch_size=batch_size, block_size=block_size)\n",
    "\n",
    "    # Forward\n",
    "    logits = model(xb)  # shape: (B, T, V)\n",
    "\n",
    "    # Convert targets to one-hot and compute CE loss\n",
    "    targets_oh = to_one_hot(yb, GPT_CONFIG_124M['vocab_size'])\n",
    "    loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "\n",
    "    # Backward + step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Logging\n",
    "    if step % print_every == 0 or step == 1:\n",
    "        print(f\"step {step:4d}/{max_steps} — loss = {loss.item():.4f}\")\n",
    "\n",
    "print('Training loop finished (demo).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fc801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Text generation helper\n",
    "def generate_text(model, start_tokens, max_tokens=50, temperature=0.8):\n",
    "    \"\"\"Generate text from the model, starting with start_tokens.\"\"\"\n",
    "    model_input = start_tokens.copy()\n",
    "    generated = []\n",
    "    \n",
    "    for _ in range(max_tokens):\n",
    "        # Create batch with single sequence\n",
    "        x = np.array(model_input)[None, :]  # Shape: (1, T)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        \n",
    "        # Get logits for the next token (last position)\n",
    "        next_logits = logits[0, -1, :]  # Shape: (vocab_size,)\n",
    "        \n",
    "        # Apply temperature\n",
    "        next_logits = next_logits.data / temperature\n",
    "        \n",
    "        # Convert to probabilities\n",
    "        probs = np.exp(next_logits - np.max(next_logits))\n",
    "        probs = probs / np.sum(probs)\n",
    "        \n",
    "        # Sample from distribution\n",
    "        next_token = np.random.choice(len(probs), p=probs)\n",
    "        \n",
    "        generated.append(next_token)\n",
    "        model_input.append(next_token)\n",
    "        \n",
    "        # Maintain context size by sliding window if needed\n",
    "        if len(model_input) > block_size:\n",
    "            model_input = model_input[-block_size:]\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# Function to format tokens as text\n",
    "def tokens_to_text(tokens):\n",
    "    return enc.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d6104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m optimizer.zero_grad()\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m targets_oh = to_one_hot(yb, GPT_CONFIG_124M[\u001b[33m'\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     35\u001b[39m loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mGPT2.__call__\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     23\u001b[39m batch_size , seq_len = in_idx.shape \n\u001b[32m     24\u001b[39m tok_embeds = \u001b[38;5;28mself\u001b[39m.tok_emb(in_idx) \n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m pos_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_emb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m x = tok_embeds + pos_embeds \u001b[38;5;66;03m# broadcasting will happen here \u001b[39;00m\n\u001b[32m     29\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/nnetflow/nnetflow/layers.py:172\u001b[39m, in \u001b[36mEmbedding.__call__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mtuple\u001b[39m]) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     embedded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/nnetflow/nnetflow/engine.py:589\u001b[39m, in \u001b[36mTensor.__getitem__\u001b[39m\u001b[34m(self, slices)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, slices: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m, Tuple]) -> \u001b[33m'\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     out = Tensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m]\u001b[49m, (\u001b[38;5;28mself\u001b[39m,), \u001b[33m'\u001b[39m\u001b[33mslice\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_backward\u001b[39m():\n\u001b[32m    592\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.requires_grad:\n\u001b[32m    593\u001b[39m             \u001b[38;5;66;03m# Create a grad array of zeros and \"scatter\" out.grad\u001b[39;00m\n\u001b[32m    594\u001b[39m             \u001b[38;5;66;03m# into the locations specified by the slice\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# --- Extended training loop with text generation\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 3e-4\n",
    "batch_size = 32\n",
    "block_size = 128  # context length for training\n",
    "max_epochs = 10   # train for multiple epochs\n",
    "print_interval = 5.0  # seconds between status updates\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = nf_optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop with periodic text generation\n",
    "print(\"Starting training...\")\n",
    "epoch = 0\n",
    "step = 0\n",
    "last_print_time = time.time()\n",
    "running_loss = 0.0\n",
    "samples_since_print = 0\n",
    "\n",
    "# Get validation context for generating samples\n",
    "val_context = val_ids[:block_size].tolist()  # Get some validation text for consistency\n",
    "\n",
    "while epoch < max_epochs:\n",
    "    # Get batch and prepare targets\n",
    "    xb, yb = get_batch(split='train', batch_size=batch_size, block_size=block_size)\n",
    "    \n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    logits = model(xb)\n",
    "    targets_oh = to_one_hot(yb, GPT_CONFIG_124M['vocab_size'])\n",
    "    loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "    \n",
    "    # Backward + step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Accumulate loss\n",
    "    running_loss += loss.item()\n",
    "    samples_since_print += batch_size\n",
    "    \n",
    "    # Print status and generate text periodically\n",
    "    current_time = time.time()\n",
    "    if current_time - last_print_time > print_interval:\n",
    "        # Calculate average loss\n",
    "        avg_loss = running_loss / samples_since_print\n",
    "        \n",
    "        # Generate sample text\n",
    "        generated_tokens = generate_text(\n",
    "            model, \n",
    "            start_tokens=val_context,\n",
    "            max_tokens=100,\n",
    "            temperature=0.8\n",
    "        )\n",
    "        sample_text = tokens_to_text(generated_tokens)\n",
    "        \n",
    "        # Print status\n",
    "        print(f\"\\nEpoch {epoch+1}/{max_epochs}, Step {step}, Loss: {avg_loss:.4f}\")\n",
    "        print(\"\\nGenerated sample:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(sample_text)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Reset accumulators\n",
    "        running_loss = 0.0\n",
    "        samples_since_print = 0\n",
    "        last_print_time = current_time\n",
    "    \n",
    "    # Update counters\n",
    "    step += 1\n",
    "    \n",
    "    # Check if epoch is complete (processed all training data)\n",
    "    if (step * batch_size) >= len(train_ids):\n",
    "        epoch += 1\n",
    "        print(f\"\\nCompleted epoch {epoch}/{max_epochs}\")\n",
    "        # Optional: shuffle data or reset counters as needed\n",
    "\n",
    "print('\\nTraining finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a5cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Training interrupted due to error: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining interrupted due to error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    106\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining finished!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m optimizer.zero_grad()\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m targets_oh = to_one_hot(yb, GPT_CONFIG_TINY[\u001b[33m'\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     52\u001b[39m loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mGPT2.__call__\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m     23\u001b[39m batch_size , seq_len = in_idx.shape \n\u001b[32m     24\u001b[39m tok_embeds = \u001b[38;5;28mself\u001b[39m.tok_emb(in_idx) \n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m pos_embeds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpos_emb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m x = tok_embeds + pos_embeds \u001b[38;5;66;03m# broadcasting will happen here \u001b[39;00m\n\u001b[32m     29\u001b[39m x = \u001b[38;5;28mself\u001b[39m.drop_emb(x) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/nnetflow/nnetflow/layers.py:172\u001b[39m, in \u001b[36mEmbedding.__call__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mtuple\u001b[39m]) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     embedded = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/nnetflow/nnetflow/engine.py:589\u001b[39m, in \u001b[36mTensor.__getitem__\u001b[39m\u001b[34m(self, slices)\u001b[39m\n\u001b[32m    588\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, slices: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m, Tuple]) -> \u001b[33m'\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m     out = Tensor(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslices\u001b[49m\u001b[43m]\u001b[49m, (\u001b[38;5;28mself\u001b[39m,), \u001b[33m'\u001b[39m\u001b[33mslice\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_backward\u001b[39m():\n\u001b[32m    592\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.requires_grad:\n\u001b[32m    593\u001b[39m             \u001b[38;5;66;03m# Create a grad array of zeros and \"scatter\" out.grad\u001b[39;00m\n\u001b[32m    594\u001b[39m             \u001b[38;5;66;03m# into the locations specified by the slice\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# --- Memory-efficient training loop with gradient clipping\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 1e-3              # Slightly higher learning rate for smaller model\n",
    "batch_size = 16        # Reduced batch size\n",
    "block_size = 64        # Smaller context window (matching tiny config)\n",
    "max_epochs = 10\n",
    "print_interval = 5.0   # seconds between status updates\n",
    "grad_clip = 1.0        # Maximum gradient norm\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = nf_optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def clip_grad_norm(parameters, max_norm):\n",
    "    \"\"\"Clips gradient norm of parameters.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        if p.grad is not None:\n",
    "            total_norm += np.sum(p.grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    if clip_coef < 1:\n",
    "        for p in parameters:\n",
    "            if p.grad is not None:\n",
    "                p.grad *= clip_coef\n",
    "\n",
    "# Training loop with periodic text generation\n",
    "print(\"Starting training...\")\n",
    "epoch = 0\n",
    "step = 0\n",
    "last_print_time = time.time()\n",
    "running_loss = 0.0\n",
    "samples_since_print = 0\n",
    "\n",
    "# Get a shorter validation context\n",
    "val_context = val_ids[:32].tolist()  # Shorter context for generation\n",
    "\n",
    "try:\n",
    "    while epoch < max_epochs:\n",
    "        # Get batch and prepare targets\n",
    "        xb, yb = get_batch(split='train', batch_size=batch_size, block_size=block_size)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        logits = model(xb)\n",
    "        targets_oh = to_one_hot(yb, GPT_CONFIG_TINY['vocab_size'])\n",
    "        loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "        \n",
    "        # Backward + clip gradients + step\n",
    "        loss.backward()\n",
    "        clip_grad_norm(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        samples_since_print += batch_size\n",
    "        \n",
    "        # Print status and generate text periodically\n",
    "        current_time = time.time()\n",
    "        if current_time - last_print_time > print_interval:\n",
    "            # Calculate average loss\n",
    "            avg_loss = running_loss / samples_since_print\n",
    "            \n",
    "            # Generate sample text\n",
    "            generated_tokens = generate_text(\n",
    "                model, \n",
    "                start_tokens=val_context,\n",
    "                max_tokens=50,  # Generate shorter samples\n",
    "                temperature=0.8\n",
    "            )\n",
    "            sample_text = tokens_to_text(generated_tokens)\n",
    "            \n",
    "            # Print status\n",
    "            print(f\"\\nEpoch {epoch+1}/{max_epochs}, Step {step}, Loss: {avg_loss:.4f}\")\n",
    "            print(\"\\nGenerated sample:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(sample_text)\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Reset accumulators\n",
    "            running_loss = 0.0\n",
    "            samples_since_print = 0\n",
    "            last_print_time = current_time\n",
    "            \n",
    "            # Force garbage collection to help memory usage\n",
    "            import gc\n",
    "            gc.collect()\n",
    "        \n",
    "        # Update counters\n",
    "        step += 1\n",
    "        \n",
    "        # Check if epoch is complete (processed all training data)\n",
    "        if (step * batch_size) >= len(train_ids):\n",
    "            epoch += 1\n",
    "            print(f\"\\nCompleted epoch {epoch}/{max_epochs}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training interrupted due to error: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "print('\\nTraining finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Memory-efficient training loop\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 1e-3              # Slightly higher learning rate for smaller model\n",
    "batch_size = 16        # Reduced batch size\n",
    "block_size = 32        # Even smaller context window for testing\n",
    "max_epochs = 10\n",
    "print_interval = 5.0   # seconds between status updates\n",
    "grad_clip = 1.0        # Maximum gradient norm\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = nf_optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def clip_grad_norm(parameters, max_norm):\n",
    "    \"\"\"Clips gradient norm of parameters.\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        if p.grad is not None:\n",
    "            total_norm += np.sum(p.grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    if clip_coef < 1:\n",
    "        for p in parameters:\n",
    "            if p.grad is not None:\n",
    "                p.grad *= clip_coef\n",
    "\n",
    "# First, try a single forward/backward pass to verify everything works\n",
    "print(\"Testing forward/backward pass...\")\n",
    "try:\n",
    "    # Get a small batch\n",
    "    xb, yb = get_batch(split='train', batch_size=2, block_size=block_size)\n",
    "    print(f\"Input shape: {xb.shape}\")\n",
    "    \n",
    "    # Forward\n",
    "    logits = model(xb)\n",
    "    print(f\"Output logits shape: {logits.shape}\")\n",
    "    \n",
    "    # Loss\n",
    "    targets_oh = to_one_hot(yb, GPT_CONFIG_TINY['vocab_size'])\n",
    "    loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "    print(f\"Initial loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    print(\"Backward pass successful!\")\n",
    "    \n",
    "    # Check gradients\n",
    "    has_grad = any(p.grad is not None and np.any(p.grad != 0) for p in model.parameters())\n",
    "    print(f\"Gradients present and nonzero: {has_grad}\")\n",
    "    \n",
    "    # Clear gradients\n",
    "    optimizer.zero_grad()\n",
    "    print(\"\\nTest successful! Starting training...\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Test failed with error: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Training loop with periodic text generation\n",
    "print(\"Starting training...\")\n",
    "epoch = 0\n",
    "step = 0\n",
    "last_print_time = time.time()\n",
    "running_loss = 0.0\n",
    "samples_since_print = 0\n",
    "\n",
    "# Get a shorter validation context\n",
    "val_context = val_ids[:block_size].tolist()  # Shorter context for generation\n",
    "\n",
    "try:\n",
    "    while epoch < max_epochs:\n",
    "        # Get batch and prepare targets\n",
    "        xb, yb = get_batch(split='train', batch_size=batch_size, block_size=block_size)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        logits = model(xb)\n",
    "        targets_oh = to_one_hot(yb, GPT_CONFIG_TINY['vocab_size'])\n",
    "        loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "        \n",
    "        # Backward + clip gradients + step\n",
    "        loss.backward()\n",
    "        clip_grad_norm(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        samples_since_print += batch_size\n",
    "        \n",
    "        # Print status and generate text periodically\n",
    "        current_time = time.time()\n",
    "        if current_time - last_print_time > print_interval:\n",
    "            # Calculate average loss\n",
    "            avg_loss = running_loss / samples_since_print\n",
    "            \n",
    "            # Generate sample text\n",
    "            generated_tokens = generate_text(\n",
    "                model, \n",
    "                start_tokens=val_context,\n",
    "                max_tokens=50,  # Generate shorter samples\n",
    "                temperature=0.8\n",
    "            )\n",
    "            sample_text = tokens_to_text(generated_tokens)\n",
    "            \n",
    "            # Print status\n",
    "            print(f\"\\nEpoch {epoch+1}/{max_epochs}, Step {step}, Loss: {avg_loss:.4f}\")\n",
    "            print(\"\\nGenerated sample:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(sample_text)\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Reset accumulators\n",
    "            running_loss = 0.0\n",
    "            samples_since_print = 0\n",
    "            last_print_time = current_time\n",
    "            \n",
    "            # Force garbage collection to help memory usage\n",
    "            import gc\n",
    "            gc.collect()\n",
    "        \n",
    "        # Update counters\n",
    "        step += 1\n",
    "        \n",
    "        # Check if epoch is complete (processed all training data)\n",
    "        if (step * batch_size) >= len(train_ids):\n",
    "            epoch += 1\n",
    "            print(f\"\\nCompleted epoch {epoch}/{max_epochs}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training interrupted due to error: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "print('\\nTraining finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ee2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Memory-efficient training loop with debug printing\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Hyperparameters - ensure block_size < context_length\n",
    "lr = 1e-3\n",
    "batch_size = 4        # Start very small\n",
    "block_size = 64       # Must be less than context_length (128)\n",
    "max_epochs = 10\n",
    "print_interval = 5.0\n",
    "grad_clip = 1.0\n",
    "\n",
    "# Rebuild model and optimizer\n",
    "print(\"Initializing fresh model and optimizer...\")\n",
    "model = GPT2(GPT_CONFIG_TINY)\n",
    "optimizer = nf_optim.Adam(model.parameters(), lr=lr)\n",
    "print(f\"Model parameter count: {sum(t.data.size for t in model.parameters()):,}\")\n",
    "\n",
    "# First, verify shapes with debug printing\n",
    "print(\"\\nTesting shapes with a tiny batch...\")\n",
    "try:\n",
    "    # Get a minimal test batch\n",
    "    xb, yb = get_batch(split='train', batch_size=2, block_size=32)  # Start with very small test\n",
    "    print(f\"Input batch shape: {xb.shape}\")\n",
    "    \n",
    "    # Get positional indices (debug)\n",
    "    positions = np.arange(xb.shape[1])\n",
    "    print(f\"Position indices shape: {positions.shape}, max index: {positions.max()}\")\n",
    "    print(f\"Position embedding weight shape: {model.pos_emb.weight.shape}\")\n",
    "    \n",
    "    # Forward pass with shape checking\n",
    "    tok_embeds = model.tok_emb(xb)\n",
    "    print(f\"Token embeddings shape: {tok_embeds.shape}\")\n",
    "    \n",
    "    pos_embeds = model.pos_emb(positions)\n",
    "    print(f\"Position embeddings shape: {pos_embeds.shape}\")\n",
    "    \n",
    "    # Full forward pass\n",
    "    logits = model(xb)\n",
    "    print(f\"Output logits shape: {logits.shape}\")\n",
    "    \n",
    "    # Loss calculation\n",
    "    targets_oh = to_one_hot(yb, GPT_CONFIG_TINY['vocab_size'])\n",
    "    loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "    print(f\"Initial loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Test backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    print(\"\\nShape test successful! Starting training...\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Shape test failed with error: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Training loop with periodic text generation\n",
    "print(\"Starting training...\")\n",
    "epoch = 0\n",
    "step = 0\n",
    "last_print_time = time.time()\n",
    "running_loss = 0.0\n",
    "samples_since_print = 0\n",
    "\n",
    "# Get a shorter validation context\n",
    "val_context = val_ids[:32].tolist()  # Shorter context for generation\n",
    "\n",
    "try:\n",
    "    while epoch < max_epochs:\n",
    "        # Get batch and prepare targets\n",
    "        xb, yb = get_batch(split='train', batch_size=batch_size, block_size=block_size)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        logits = model(xb)\n",
    "        targets_oh = to_one_hot(yb, GPT_CONFIG_TINY['vocab_size'])\n",
    "        loss = nf_losses.cross_entropy_loss(logits, targets_oh)\n",
    "        \n",
    "        # Backward + clip gradients + step\n",
    "        loss.backward()\n",
    "        clip_grad_norm(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        samples_since_print += batch_size\n",
    "        \n",
    "        # Print status and generate text periodically\n",
    "        current_time = time.time()\n",
    "        if current_time - last_print_time > print_interval:\n",
    "            # Calculate average loss\n",
    "            avg_loss = running_loss / samples_since_print\n",
    "            \n",
    "            # Generate sample text\n",
    "            generated_tokens = generate_text(\n",
    "                model, \n",
    "                start_tokens=val_context[:32],  # Keep context smaller than block_size\n",
    "                max_tokens=32,  # Generate shorter samples\n",
    "                temperature=0.8\n",
    "            )\n",
    "            sample_text = tokens_to_text(generated_tokens)\n",
    "            \n",
    "            # Print status\n",
    "            print(f\"\\nEpoch {epoch+1}/{max_epochs}, Step {step}, Loss: {avg_loss:.4f}\")\n",
    "            print(\"\\nGenerated sample:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(sample_text)\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Reset accumulators\n",
    "            running_loss = 0.0\n",
    "            samples_since_print = 0\n",
    "            last_print_time = current_time\n",
    "            \n",
    "            # Force garbage collection\n",
    "            import gc\n",
    "            gc.collect()\n",
    "        \n",
    "        # Update counters\n",
    "        step += 1\n",
    "        \n",
    "        # Check if epoch is complete\n",
    "        if (step * batch_size) >= len(train_ids):\n",
    "            epoch += 1\n",
    "            print(f\"\\nCompleted epoch {epoch}/{max_epochs}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training interrupted due to error: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "print('\\nTraining finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbcb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
