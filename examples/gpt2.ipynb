{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1e09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import sys \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50534138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parent directory path\n",
    "parent_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath('.'))), 'nnetflow')\n",
    "# Add parent directory to Python path if not already there\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df75ee79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/njue/.dev/nnetflow'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df417f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/njue/.dev/nnetflow', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/home/njue/.dev/nnetflow/env/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605fe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnetflow.engine import Tensor \n",
    "from nnetflow import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74959ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f7a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87841cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84567e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward:\n",
    "    def __init__(self,cfg:dict): \n",
    "        super().__init__() \n",
    "        self.layers = [\n",
    "            layers.Linear(cfg['emb_dim'],4*cfg['emb_dim']),\n",
    "            layers.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])\n",
    "        ]\n",
    "    def __call__(self,x): \n",
    "        # Fix indexing syntax\n",
    "        return self.layers[1](self.layers[0](x).gelu())\n",
    "    def parameters(self):\n",
    "        parameters = [] \n",
    "        parameters.extend(self.layers[0].parameters())\n",
    "        parameters.extend(self.layers[1].parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aba6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention:\n",
    "    def __init__(self,d_in,d_out,context_length,num_heads,dropout,qkv_bias=False):\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\" \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads \n",
    "        self.head_dim = d_out // num_heads \n",
    "        self.W_query = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.W_key = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.W_value = layers.Linear(d_in,d_out,bias=qkv_bias) \n",
    "        self.out_proj = layers.Linear(d_out,d_out)\n",
    "        self.dropout = layers.Dropout(dropout) \n",
    "        mask = np.triu(np.ones((context_length, context_length)), k=1)\n",
    "        self.mask = Tensor(mask,requires_grad=False) \n",
    "    \n",
    "    def __call__(self,x):\n",
    "        B,T,D_in = x.shape \n",
    "        Q = self.W_query(x) # (B,T,D_out) \n",
    "        K = self.W_key(x) \n",
    "        V = self.W_value(x) \n",
    "        Q = Q.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "        K = K.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "        V = V.reshape((B,T,self.num_heads,self.head_dim)).transpose((0,2,1,3))  # Fix transpose axes\n",
    "\n",
    "        # attention scores \n",
    "        attn_scores = (Q @ K.transpose((0,1,3,2))) / (self.head_dim ** 0.5)  # Fix transpose axes\n",
    "        mask = self.mask[:T,:T].bool()\n",
    "        attn_scores = attn_scores.masked_fill(mask[None,None,:,:],float('-inf'))\n",
    "        #softmax and dropout \n",
    "        attn_weights = attn_scores.softmax(axis=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context = attn_weights @ V \n",
    "        context = context.transpose((0,2,1,3)).reshape((B,T,self.d_out))  # Fix transpose and reshape\n",
    "        context = self.out_proj(context) \n",
    "        return context \n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = [] \n",
    "        parameters.extend(self.W_key.parameters())\n",
    "        parameters.extend(self.W_query.parameters())\n",
    "        parameters.extend(self.W_value.parameters())\n",
    "        parameters.extend(self.out_proj.parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock: \n",
    "    def __init__(self,config:dict):\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in= config['emb_dim'],\n",
    "            d_out = config['emb_dim'], \n",
    "            context_length=config['context_length'], \n",
    "            num_heads = config['n_heads'], \n",
    "            dropout = config['drop_rate'], \n",
    "            qkv_bias=config['qkv_bias'] \n",
    "        ) \n",
    "\n",
    "        self.ff = FeedForward(config) \n",
    "        # Add embedding dimension to LayerNorm\n",
    "        self.norm1 = layers.LayerNorm(dim=config['emb_dim']) \n",
    "        self.norm2 = layers.LayerNorm(dim=config['emb_dim']) \n",
    "        self.drop_shortcut = layers.Dropout(config['drop_rate']) \n",
    "    def __call__(self,x):\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        # Add second normalization and feedforward\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x \n",
    "\n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        parameters.extend(self.ff.parameters())\n",
    "        parameters.extend(self.norm1.parameters())\n",
    "        parameters.extend(self.norm2.parameters())\n",
    "        parameters.extend(self.att.parameters())\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dc21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self,config:dict): \n",
    "        self.tok_emb = layers.Embedding(config['vocab_size'],config['emb_dim']) \n",
    "        self.pos_emb = layers.Embedding(config['context_length'],config['emb_dim'])\n",
    "        self.drop_emb = layers.Dropout(config['drop_rate']) \n",
    "        self.trf_blocks = [TransformerBlock(config) for _ in range(config['n_layers'])]\n",
    "        self.final_norm = layers.LayerNorm(dim=config['emb_dim'])  # Add embedding dimension\n",
    "        self.out_head = layers.Linear( \n",
    "            config['emb_dim'], config['vocab_size'],bias=False\n",
    "        )\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] \n",
    "        params.extend(self.tok_emb.parameters())\n",
    "        params.extend(self.pos_emb.parameters())\n",
    "        params.extend(self.final_norm.parameters())\n",
    "        params.extend(self.out_head.parameters())\n",
    "        for block in self.trf_blocks:\n",
    "            params.extend(block.parameters())\n",
    "        return params\n",
    "    \n",
    "    def __call__(self,in_idx:Tensor): \n",
    "        batch_size , seq_len = in_idx.shape \n",
    "        tok_embeds = self.tok_emb(in_idx) \n",
    "        pos_embeds = self.pos_emb(\n",
    "            Tensor(np.arange(seq_len))\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds # broadcasting will happen here \n",
    "        x = self.drop_emb(x) \n",
    "        for block in self.trf_blocks:\n",
    "            x = block(x) \n",
    "        x = self.final_norm(x) \n",
    "        logits = self.out_head(x) \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41aaf4b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '1024' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mGPT2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGPT_CONFIG_124M\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mGPT2.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.pos_emb = layers.Embedding(config[\u001b[33m'\u001b[39m\u001b[33mcontext_length\u001b[39m\u001b[33m'\u001b[39m],config[\u001b[33m'\u001b[39m\u001b[33memb_dim\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28mself\u001b[39m.drop_emb = layers.Dropout(config[\u001b[33m'\u001b[39m\u001b[33mdrop_rate\u001b[39m\u001b[33m'\u001b[39m]) \n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mself\u001b[39m.trf_blocks = [\u001b[43mTransformerBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[33m'\u001b[39m\u001b[33mn_layers\u001b[39m\u001b[33m'\u001b[39m])] \u001b[38;5;66;03m#imprement transformer block later \u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mself\u001b[39m.final_norm = layers.LayerNorm() \u001b[38;5;66;03m# the way i have impremented layernorm no need to pass config['emb_dim'] :(  \u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.out_head = layers.Linear( \n\u001b[32m      9\u001b[39m     config[\u001b[33m'\u001b[39m\u001b[33memb_dim\u001b[39m\u001b[33m'\u001b[39m], config[\u001b[33m'\u001b[39m\u001b[33mvocab_size\u001b[39m\u001b[33m'\u001b[39m],bias=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mTransformerBlock.__init__\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,config:\u001b[38;5;28mdict\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mself\u001b[39m.att = \u001b[43mMultiHeadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43md_in\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43memb_dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43md_out\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43memb_dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontext_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_heads\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdrop_rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mqkv_bias\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     12\u001b[39m     \u001b[38;5;28mself\u001b[39m.ff = FeedForward(config) \n\u001b[32m     13\u001b[39m     \u001b[38;5;28mself\u001b[39m.norm1 = layers.LayerNorm() \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mMultiHeadAttention.__init__\u001b[39m\u001b[34m(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.out_proj = layers.Linear(d_out,d_out)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.dropout = layers.Dropout(dropout) \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m mask = np.triu(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcontext_length\u001b[49m\u001b[43m)\u001b[49m,k=\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# k is the diagonal like diagonal i beleaf ? i will confim \u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mself\u001b[39m.mask = Tensor(mask,requires_grad=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.dev/nnetflow/env/lib/python3.12/site-packages/numpy/_core/numeric.py:233\u001b[39m, in \u001b[36mones\u001b[39m\u001b[34m(shape, dtype, order, device, like)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ones_with_like(\n\u001b[32m    230\u001b[39m         like, shape, dtype=dtype, order=order, device=device\n\u001b[32m    231\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m a = \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m multiarray.copyto(a, \u001b[32m1\u001b[39m, casting=\u001b[33m'\u001b[39m\u001b[33munsafe\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mTypeError\u001b[39m: Cannot interpret '1024' as a data type"
     ]
    }
   ],
   "source": [
    "model = GPT2(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0157c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
